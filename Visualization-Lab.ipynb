{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP541  Spring 2018 Visualization Lab\n",
    "\n",
    "* In this Lab you will implement some methods and experiment with several visualization techniques.<br/>\n",
    "* Please read all the instructions and comments carefully.\n",
    "* **IMPORTANT: NEXT STEP MAY TAKE A LITTLE BIT LONGER. PLEASE WAIT UNTILL ALL YOUR PACKAGES are installed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may comment out that cell after installing all the necessary packages\n",
    "for p in (\"Knet\",\"ArgParse\",\"Images\",\"Plots\",\"Plotly\",\"MAT\")\n",
    "    Pkg.installed(p) == nothing && Pkg.add(p)\n",
    "end\n",
    "# PLEASE WAIT TO FINISH PACKAGE INSTALLATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A bit of setup as usual\n",
    "using Knet, ArgParse,Images,Plots,MAT\n",
    "const modelurl = \"http://www.vlfeat.org/matconvnet/models/imagenet-resnet-101-dag.mat\"\n",
    "const imgurls = [(\"https://github.com/BVLC/caffe/raw/master/examples/images/cat.jpg\", 284),\n",
    "                 (\"http://home.mweb.co.za/pa/pak04857/uniweb/animalimages/elephantthumb.jpg\",387),\n",
    "                 (\"http://farm1.static.flickr.com/64/168461914_afe4852372.jpg\",386),\n",
    "                 (\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcT_zYiGPRndbvGTKqff5PVp7gvOO1SWGprhnI9rcDFxmXEAx9SIgg\", 228),\n",
    "                ]\n",
    "plotlyjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes a url or file name and returns an Array{RGB} \n",
    "# It does not resize or modify the original image. \n",
    "function loadimage(img)\n",
    "    global _imgcache\n",
    "    if contains(img,\"://\")\n",
    "        info(\"Downloading $img\")\n",
    "        a0 = load(download(img))\n",
    "    else\n",
    "        a0 = load(img)\n",
    "    end\n",
    "    new_size = ntuple(i->div(size(a0,i)*224,minimum(size(a0))),2)\n",
    "    a1 = Images.imresize(a0, new_size)\n",
    "    i1 = div(size(a1,1)-224,2)\n",
    "    j1 = div(size(a1,2)-224,2)\n",
    "    b10 = a1[i1+1:i1+224,j1+1:j1+224]\n",
    "    return b10\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It takes output of loadimage and \n",
    "# modifies it by resizing and subtracting average image \n",
    "# provided my resnet file \n",
    "function prepare_img(img,averageImage)\n",
    "    # ad-hoc solution for Mac-OS image\n",
    "    macfix = convert(Array{FixedPointNumbers.Normed{UInt8,8},3}, channelview(img))\n",
    "    c1 = permutedims(macfix, (3,2,1))\n",
    "    d1 = convert(Array{Float32}, c1)\n",
    "    e1 = reshape(d1[:,:,1:3], (224,224,3,1))     \n",
    "    f1 = (255 * e1 .- averageImage) \n",
    "    g1 = permutedims(f1, [2,1,3,4])\n",
    "    return g1\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Occlusion Experiments\n",
    "You are going to occlude input image from different regions and <br\\>\n",
    "observe the probability of predicted class of occluded image.\n",
    "\n",
    "For Occlusion Experiments, you need to:\n",
    "* Complete ```pertubeimg``` method.\n",
    "* Update the ```results``` matrix with the probability of the target class you get with the occluded image. Target class is the class the model predicts for the original image.<br\\>\n",
    "  \n",
    "\n",
    "**```pertubeimg``` method**\n",
    "\n",
    "It is used to obtain occluded versions of the orjinal image.\n",
    "You are going to modify the input image by moving occlusion box through the image. You will return ```occluded_images``` array which stores  modified images, each of which has is  a ```KnetArray{Float32,4}``` array. The color of the occlusion box will be the mean color of original image.\n",
    "\n",
    "\n",
    "Parameters of ```pertubeimg``` method: <br\\>\n",
    "* ```img```    : output of ```loadimage``` method. It's type is Array{RGB}. \n",
    "* ```avgimg``` : Average pixel values for each channel of RGB mapping. Obtained from the model file in main function.\n",
    "* ```atype```  : KnetArray{Float32} or Array{Float32}\n",
    "* ```psize```  : (w,h) tuple defining the size of occlusion box. \n",
    "\n",
    "**Hint**: You can use ```mean``` function to find the mean pixel values of image <br\\>\n",
    "**Hint-2**: Double check that you are occluding only a single region at a time in the input image <br\\> \n",
    "**Hint-3**: You may want to use ```prepare_img``` method to convert your occluded image to desired type before pushing it to ```occluded_images``` .<br\\> \n",
    "\n",
    "**Updating ```result``` matrix** <br\\>\n",
    "Inside the main function, you will classify each occluded image stored in ```occluded_images``` array. \n",
    "After each classification, you will store the probability of target class in the results matrix at the correct position. ```results``` is an 2D array, where each point corresponds to a occlusion region in the original image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for occlusion visualization. It takes \n",
    "# original image (output of loadimage) as\n",
    "function pertubeimg(img,avgimg,atype;psize=(8,8))\n",
    "    w,h = size(img)\n",
    "    occluded_images = Any[]\n",
    "    # we use these values in our occlusion box \n",
    "    meanvals = mean(img)\n",
    "    occbox  = zeros(RGB{Float64},psize) .+ meanvals\n",
    "    for c1=1:psize[1]:w\n",
    "        occluded_images_cols = Any[]\n",
    "        for c2=1:psize[2]:h\n",
    "            # ANSWERS\n",
    "            image=copy(img)\n",
    "            if c1>w-psize[1] && c2>h-psize[2]\n",
    "                image[c1:w,c2:h]=occbox\n",
    "                elseif c1>w-psize[1] && c2<=h-psize[2]\n",
    "                image[c1:w,c2:c2+psize[2]-1]=occbox\n",
    "                elseif c1<=w-psize[1] && c2>h-psize[2]\n",
    "                image[c1:c1+psize[1]-1,c2:h]=occbox\n",
    "                else \n",
    "                image[c1:c1+psize[1]-1,c2:c2+psize[2]-1]=occbox\n",
    "            end\n",
    "            image1=prepare_img(image,avgimg)\n",
    "            occluded_image=convert(atype,image1)\n",
    "            push!(occluded_images_cols,occluded_image)            \n",
    "            # ANSWERE\n",
    "        end\n",
    "        push!(occluded_images,occluded_images_cols)\n",
    "    end\n",
    "    return occluded_images\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saliency Maps\n",
    "We will compute saliency maps described in section 3.1 of [1].<br\\>\n",
    "\n",
    "First, you need to compute the **gradient of the image** with respect to the\n",
    "unnormalized class score, not with respect to the normalized class probablitity.\n",
    "To implement ```compute_saliency``` you need to understand and choose \"correct\" parts from ```classify``` function given above.\n",
    "\n",
    "Hint: After implementing forward calculation Knet's ```grad``` function takes care gradients.\n",
    "\n",
    "[1] Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman. \"Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps\", ICLR Workshop 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the forward calculations of saliency\n",
    "function compute_saliency(input_image, model_weights, gold_label, ms, f)\n",
    "    #ANSWERS\n",
    "    y1 = f(model_weights,input_image,ms)\n",
    "    return y1[gold_label]\n",
    "    #ANSWERE\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_saliency = grad(compute_saliency);#YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not touch that function\n",
    "mnistview(x,i)=colorview(Gray,permutedims(x[:,:,1,i],(2,1)))\n",
    "function visualize_saliency(gimg1)\n",
    "    g1 = abs.(gimg1);\n",
    "    g2 = maximum(Array(g1), 3)\n",
    "    g2[g2 .> 1.1f-3] += 0.1\n",
    "    display(mnistview(g2,1))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weight Visualization\n",
    "We will visualize the weights of specific layer's of Resnet101 model. <br\\>\n",
    "\n",
    "To do that, the only thing you need to to is complete ```weightvis``` method. <br\\>\n",
    "For the assignment, you need to visualize the first layer of the Resnet. <br\\>\n",
    "You can check the layers of Resnet101 model by looking the utility methods <br\\>\n",
    "defined at the bottom of this notebook. \n",
    "Parameters of the ```weightvis```:\n",
    "* ```w```    : Weight arrays. \n",
    "* ```ms```   : Resnet meta parameters required for batchnorm\n",
    "* ```mode``` : 1 is test mode 0 is train mode\n",
    "* ```layernum```: ID of target layer where you visualize the weigths. Do not need to change it\n",
    "* ```scale```: resizing scale used while visualizing weights. For example, if the scale is (4,4) then,  \n",
    "    the target weight matrix,wx, will be resized 4*size(wx,1) x 4*size(wx,2)<br\\>\n",
    "    **Hint**: You need to shift all the  weight values between 0 and 1.<br\\>\n",
    "    **Hint-2**: You may want to look at RGB type and colorview method defined in Images package.<br\\>\n",
    "    **Hint-3**: To resize the image, you may want to lookat imresize method efined in Images package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function weightvis(w,ms;mode=1,layernum=1,scale=(4,4))\n",
    "    # 1) Convert your weight to Array{Float32} type\n",
    "    # 2) Clamp your elements in weight array so that all of them will be greater than or equal to zero\n",
    "    # 3) If you have N^2 filters in that layer, you will display them in a NxN grid. You will store each\n",
    "    # filter in a result array. \n",
    "    # 4) You will resize each filter by using scale parameter. You may want to use imresize method. \n",
    "    IJulia.clear_output(true)\n",
    "    result = Any[]\n",
    "\n",
    "    sqrtsize =  Int(floor(sqrt(size(w[layernum],4))))\n",
    "\n",
    "    # ANSWERS\n",
    "    w1=convert(Array,w[layernum])\n",
    "    x=size(w1,1)\n",
    "    y=size(w1,2)\n",
    "    if size(w1,4)==sqrtsize^2\n",
    "        for i=1:sqrtsize\n",
    "            result_col = Any[]\n",
    "            for j=1:sqrtsize\n",
    "                R=reshape(w1[:,:,1,i*j],(x,y))\n",
    "                R=(R.-minimum(R))./(maximum(R)-minimum(R))\n",
    "                G=reshape(w1[:,:,2,i*j],(x,y))\n",
    "                G=(G.-minimum(G))./(maximum(G)-minimum(G))\n",
    "                B=reshape(w1[:,:,3,i*j],(x,y))\n",
    "                B=(B.-minimum(B))./(maximum(B)-minimum(B))\n",
    "                a=colorview(RGB,R,G,B)\n",
    "                push!(result_col,Images.imresize(a,(scale[1]*x,scale[2]*y)))\n",
    "                \n",
    "\n",
    "            end\n",
    "            push!(result,hcat(result_col...))\n",
    "        end\n",
    "    else\n",
    "        println(\"nonsquare size\")\n",
    "    end\n",
    "    # ANSWERE\n",
    "    display(vcat(result...))\n",
    "   # result1=[]\n",
    "    #for i in 1:sqrtsize:length((result...))\n",
    "     #   b=hcat(result[i:i+sqrtsize-1])\n",
    "      #  push!(result1,b)\n",
    "    #end\n",
    "    #a=vcat(result1)\n",
    "    #display(vcat(result1...))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function main(args)\n",
    "    s = ArgParseSettings()\n",
    "    s.description = \"Comp541, Spring 2018 Visualization Lab\"\n",
    "    @add_arg_table s begin\n",
    "        (\"--image\";arg_type=Int; default=2; help=\"Image file or URL chosen from the imgurls array\")\n",
    "        (\"--model\"; default=\"imagenet-resnet-101-dag\"; help=\"resnet model name\")\n",
    "        (\"--top\"; default=5; arg_type=Int; help=\"Display the top N classes\")\n",
    "        (\"--atype\"; default=(gpu()>=0 ? \"KnetArray{Float32}\" : \"Array{Float32}\"); help=\"array and float type to use\")\n",
    "        (\"--task\"; default=\"occlusion\"; help=\"type of visualization. Options: occlusion|weightvis|saliency\")\n",
    "    end\n",
    "\n",
    "    isa(args, AbstractString) && (args=split(args))\n",
    "    o = parse_args(args, s; as_symbols=true)\n",
    "    o[:image] = imgurls[o[:image]]\n",
    "    println(\"opts=\",[(k,v) for (k,v) in o]...)\n",
    "    atype = eval(parse(o[:atype]))\n",
    "    model = load_model(o[:model])\n",
    "    avgimg = model[\"meta\"][\"normalization\"][\"averageImage\"]\n",
    "    avgimg = convert(Array{Float32}, avgimg)\n",
    "    description = model[\"meta\"][\"classes\"][\"description\"]\n",
    "    w, ms = get_params(model[\"params\"], atype)\n",
    "    # get model by length of parameters\n",
    "    modeldict = Dict(\n",
    "        314 => (resnet101, \"resnet101\"))\n",
    "    !haskey(modeldict, length(w)) && error(\"wrong resnet MAT file\")\n",
    "    resnet, name = modeldict[length(w)]\n",
    "    \n",
    "    # Occlusion Experiments\n",
    "    if o[:task] == \"occlusion\"\n",
    "        oimg  = loadimage(o[:image][1]) # You need 1 for imgurl\n",
    "        oimg2 = convert(atype,prepare_img(oimg,avgimg))\n",
    "        # predictions with corresponding probabilities for original image \n",
    "        p1,s1 = classify(w,resnet,oimg2,ms)\n",
    "        # name of the class with highest probability\n",
    "        pgold,cname = p1[s1[1:o[:top]]][1],description[s1[1:o[:top]]][1]\n",
    "        println(\"top-1 class & probability of original image:\")\n",
    "        println(pgold,\"\\t\",cname)\n",
    "        # create perturbed images \n",
    "        inputs = pertubeimg(oimg,avgimg,atype;psize=(8,8))\n",
    "        # store the probability of predicted class of perturbed image. \n",
    "        result = zeros(length(inputs),length(inputs[1]))\n",
    "       \n",
    "\n",
    "        println(\"----------------------------\")\n",
    "        println(\"top-1 class of perturbed images:\")\n",
    "        for i=1:length(inputs)\n",
    "            for j=1:length(inputs[i])\n",
    "                # classify each perturbed image \n",
    "                p2,s2 = classify(w,resnet,inputs[i][j],ms)\n",
    "                # display the top class probability for perturbed img\n",
    "                output = hcat(p2[s2[1:o[:top]]], description[s2[1:o[:top]]]);\n",
    "                #println(\"i:$i, j:$j:\",output[1,:]);flush(STDOUT)                \n",
    "                  \n",
    "                # ANSWERS\n",
    "                result[i,j]=p2[s1[1]]\n",
    "                #ANSWERE\n",
    "            end\n",
    "        end\n",
    "    \n",
    "    println(\"----------------------------\")\n",
    "    println(\"result matrix:\")\n",
    "    flush(STDOUT)\n",
    "    display(result)\n",
    "    result1=zeros(size(result))\n",
    "    for i in 1:size(result)[1]\n",
    "            result1[end-i+1,:]=result[i,:]\n",
    "    end\n",
    "    \n",
    "    # plot heatmap and original image side by side \n",
    "    plot(plot(oimg,colorbar=false),heatmap(result1,c=:gray),size=(448,224))                    \n",
    "\n",
    "    elseif o[:task] == \"saliency\"\n",
    "        oimg = loadimage(o[:image][1])\n",
    "        gold_label = o[:image][2] # we need to know the correct label to calculate the loss w.r.t to it\n",
    "        oimg2 = convert(atype,prepare_img(oimg,avgimg))\n",
    "        gradients_of_image = grad_saliency(oimg2, w, gold_label, ms, resnet)\n",
    "        display(oimg)\n",
    "        visualize_saliency(gradients_of_image)\n",
    "    elseif o[:task] == \"weightvis\"\n",
    "        weightvis(w,ms)\n",
    "    else\n",
    "        error(\"You've chosen unimplemented task\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions \n",
    "Below, we add the utility functions needed through the lab. We encourage you to understand them.\n",
    "<br\\>Here is a brief list of these functions:\n",
    "* Method for loading pretrained ```resnet101``` model \n",
    "* Methods for resnet layers and batchnormalization \n",
    "* Method that returns loaded weights and batchnorm parameters\n",
    "* Most importantnly ```classify``` method, you can use directly to get a prediction for an image. \n",
    "* You may want to look at ```get_params``` and ```resnet``` methods for weight visualization subtask of the Lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESNET building functions \n",
    "# Batch Normalization Layer\n",
    "# works both for convolutional and fully connected layers\n",
    "# mode, 0=>train, 1=>test\n",
    "\n",
    "function classify(w,resnet,img,ms)\n",
    "    y1 = resnet(w,img,ms)\n",
    "    z1 = vec(Array(y1))\n",
    "    s1 = sortperm(z1,rev=true)\n",
    "    p1 = exp.(logp(z1))\n",
    "    return p1,s1\n",
    "end\n",
    "\n",
    "function bnorm(w, x, ms; mode=1, epsilon=1e-5)\n",
    "    mu, sigma = nothing, nothing\n",
    "    if mode == 0\n",
    "        d = ndims(x) == 4 ? (1,2,4) : (2,)\n",
    "        s = prod(size(x,d...))\n",
    "        mu = sum(x,d) / s\n",
    "        x0 = x .- mu\n",
    "        x1 = x0 .* x0\n",
    "        sigma = sqrt(epsilon + (sum(x1, d)) / s)\n",
    "    elseif mode == 1\n",
    "        mu = shift!(ms)\n",
    "        sigma = shift!(ms)\n",
    "    end\n",
    "\n",
    "    # we need getval in backpropagation\n",
    "    push!(ms, getval(mu), getval(sigma))\n",
    "    xhat = (x.-mu) ./ sigma\n",
    "    return w[1] .* xhat .+ w[2]\n",
    "end\n",
    "\n",
    "function reslayerx0(w,x,ms; padding=0, stride=1, mode=1)\n",
    "    b  = conv4(w[1],x; padding=padding, stride=stride)\n",
    "    bx = bnorm(w[2:3],b,ms; mode=mode)\n",
    "end\n",
    "\n",
    "function reslayerx1(w,x,ms; padding=0, stride=1, mode=1)\n",
    "    relu.(reslayerx0(w,x,ms; padding=padding, stride=stride, mode=mode))\n",
    "end\n",
    "\n",
    "function reslayerx2(w,x,ms; pads=[0,1,0], strides=[1,1,1], mode=1)\n",
    "    ba = reslayerx1(w[1:3],x,ms; padding=pads[1], stride=strides[1], mode=mode)\n",
    "    bb = reslayerx1(w[4:6],ba,ms; padding=pads[2], stride=strides[2], mode=mode)\n",
    "    bc = reslayerx0(w[7:9],bb,ms; padding=pads[3], stride=strides[3], mode=mode)\n",
    "end\n",
    "\n",
    "function reslayerx3(w,x,ms; pads=[0,0,1,0], strides=[2,2,1,1], mode=1) # 12\n",
    "    a = reslayerx0(w[1:3],x,ms; stride=strides[1], padding=pads[1], mode=mode)\n",
    "    b = reslayerx2(w[4:12],x,ms; strides=strides[2:4], pads=pads[2:4], mode=mode)\n",
    "    relu.(a .+ b)\n",
    "end\n",
    "\n",
    "function reslayerx4(w,x,ms; pads=[0,1,0], strides=[1,1,1], mode=1)\n",
    "    relu.(x .+ reslayerx2(w,x,ms; pads=pads, strides=strides, mode=mode))\n",
    "end\n",
    "\n",
    "function reslayerx5(w,x,ms; strides=[2,2,1,1], mode=1)\n",
    "    x = reslayerx3(w[1:12],x,ms; strides=strides, mode=mode)\n",
    "    for k = 13:9:length(w)\n",
    "        x = reslayerx4(w[k:k+8],x,ms; mode=mode)\n",
    "    end\n",
    "    return x\n",
    "end\n",
    "\n",
    "# mode, 0=>train, 1=>test\n",
    "function resnet101(w,x,ms; mode=1)\n",
    "    # layer 1\n",
    "    conv1 = reslayerx1(w[1:3],x,ms; padding=3, stride=2, mode=mode)\n",
    "    pool1 = pool(conv1; window=3, stride=2)\n",
    "\n",
    "    # layer 2,3,4,5\n",
    "    r2 = reslayerx5(w[4:33], pool1, ms; strides=[1,1,1,1], mode=mode)\n",
    "    r3 = reslayerx5(w[34:72], r2, ms; mode=mode)\n",
    "    r4 = reslayerx5(w[73:282], r3, ms; mode=mode)\n",
    "    r5 = reslayerx5(w[283:312], r4, ms; mode=mode)\n",
    "\n",
    "    # fully connected layer\n",
    "    pool5  = pool(r5; stride=1, window=7, mode=2)\n",
    "    fc1000 = w[313] * mat(pool5) .+ w[314]\n",
    "end\n",
    "\n",
    "_mcnurl = \"http://www.vlfeat.org/matconvnet/models\"\n",
    "_mcndir = Pkg.dir(\"Knet\",\"data\",\"imagenet\")\n",
    "\n",
    "function load_model(name)\n",
    "    global _mcncache\n",
    "    if !isdefined(:_mcncache); _mcncache=Dict(); end\n",
    "    if !haskey(_mcncache,name)\n",
    "        matfile = \"$name.mat\"\n",
    "        info(\"Loading $matfile...\")\n",
    "        path = joinpath(_mcndir,matfile)\n",
    "        if !isfile(path)\n",
    "            println(\"Should I download $matfile?\")\n",
    "            readline()[1] == 'y' || error(:ok)\n",
    "            isdir(_mcndir) || mkpath(_mcndir)\n",
    "            download(\"$_mcnurl/$matfile\",path)\n",
    "        end\n",
    "        _mcncache[name] = matread(path)\n",
    "    end\n",
    "    return _mcncache[name]\n",
    "end\n",
    "\n",
    "function get_params(params, atype)\n",
    "    len = length(params[\"value\"])\n",
    "    ws, ms = [], []\n",
    "    for k = 1:len\n",
    "        name = params[\"name\"][k]\n",
    "        value = convert(Array{Float32}, params[\"value\"][k])\n",
    "\n",
    "        if endswith(name, \"moments\")\n",
    "            push!(ms, reshape(value[:,1], (1,1,size(value,1),1)))\n",
    "            push!(ms, reshape(value[:,2], (1,1,size(value,1),1)))\n",
    "        elseif startswith(name, \"bn\")\n",
    "            push!(ws, reshape(value, (1,1,length(value),1)))\n",
    "        elseif startswith(name, \"fc\") && endswith(name, \"filter\")\n",
    "            push!(ws, transpose(reshape(value,size(value,3,4))))\n",
    "        elseif startswith(name, \"conv\") && endswith(name, \"bias\")\n",
    "            push!(ws, reshape(value, (1,1,length(value),1)))\n",
    "        else\n",
    "            push!(ws, value)\n",
    "        end\n",
    "    end\n",
    "    map(wi->convert(atype, wi), ws),\n",
    "    map(mi->convert(atype, mi), ms)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Your Code \n",
    "You can use the one line below to test your implementations.\n",
    "If you encounter with a text box asking for user input, \n",
    "please type 'y'. It will download pretrained resnet model file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK=\"weightvis\"  # other alternatives: weightvis or saliency occlusion\n",
    "main(\"--task weightvis --image 2\")# Second argument is an image index to choose from imgurls array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
